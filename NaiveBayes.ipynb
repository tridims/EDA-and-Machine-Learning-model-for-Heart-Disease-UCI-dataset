{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries for machine learing and data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# import naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_list = os.listdir(\"Dataset\")\n",
    "file_list = [file.replace(\".csv\", \"\") for file in file_list]\n",
    "\n",
    "# put file names in file_list that have world splitTrain to file_list_train\n",
    "file_list_train = [file for file in file_list if \"splitTrain\" in file]\n",
    "file_list_test = [file for file in file_list if \"splitTest\" in file]\n",
    "\n",
    "data_train = {}\n",
    "for file in file_list_train:\n",
    "    data_train[file.replace(\"splitTrain_\", \"\").replace(\"splitTrain\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n",
    "\n",
    "data_test = {}\n",
    "for file in file_list_test:\n",
    "    data_test[file.replace(\"splitTest_\", \"\").replace(\"splitTest\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import f1 score metric from sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# function to get dictionary of f1 score prediction for each data train and data test using KNeighborsClassifier\n",
    "def get_score(data_train, data_test, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "        try:\n",
    "          X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_train = data_train[key][\"HeartDisease\"]\n",
    "          X_test = data_test[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_test = data_test[key][\"HeartDisease\"]\n",
    "\n",
    "          model = modelNB()\n",
    "          model.fit(X_train, y_train)\n",
    "          y_pred = model.predict(X_test)\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "        try:\n",
    "          performanceData[key] = {'f1_score' : f1_score(y_test, y_pred)}\n",
    "          performanceData[key]['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "          performanceData[key]['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "          performanceData[key]['roc_auc_score'] = roc_auc_score(y_test, y_pred)\n",
    "          performanceData[key]['precision_score'] = precision_score(y_test, y_pred)\n",
    "          performanceData[key]['recall_score'] = recall_score(y_test, y_pred)\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "    return performanceData\n",
    "\n",
    "# function to cross validate the model using KFold\n",
    "def cross_validate(data_train, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "      try:\n",
    "        X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "        y_train = data_train[key][\"HeartDisease\"]\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True)\n",
    "        scores = cross_val_score(modelNB(), X_train, y_train, cv=kf, scoring=\"f1_macro\")\n",
    "        performanceData[key] = scores.mean()\n",
    "      except:\n",
    "        continue\n",
    "            \n",
    "    return performanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_encoded_minmaxScaled', 'df_modifiedOutlier_encoded_minmaxScaled', 'df_deleteOutlier_encoded_minmaxScaled', 'df_DF_encoded_minmaxScaled', 'df_DF_modifiedOutlier_encoded_minmaxScaled', 'df_DF_deleteOutlier_encoded_minmaxScaled', 'df_DF_encoded_stdScaled_rounded', 'df_encoded_', 'df_DF_encoded_', 'df_modifiedOutlier_encoded_', 'df_DF_modifiedOutlier_encoded_', 'df_deleteOutlier_encoded_', 'df_DF_deleteOutlier_encoded_'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing already made models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_gnb = get_score(data_train, data_test, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>[[90, 23], [19, 144]]</td>\n",
       "      <td>0.839948</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>0.883436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>[[90, 23], [21, 142]]</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.860606</td>\n",
       "      <td>0.871166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.857939</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>[[71, 42], [9, 154]]</td>\n",
       "      <td>0.786552</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.944785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.862559</td>\n",
       "      <td>[[95, 15], [14, 87]]</td>\n",
       "      <td>0.862511</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.861386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[71, 42], [10, 153]]</td>\n",
       "      <td>0.783484</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.938650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>[[95, 15], [15, 86]]</td>\n",
       "      <td>0.857561</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>[[100, 16], [16, 89]]</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>[[97, 13], [18, 83]]</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.821782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>[[96, 20], [15, 90]]</td>\n",
       "      <td>0.842365</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>[[97, 13], [19, 82]]</td>\n",
       "      <td>0.846850</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.811881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>[[95, 21], [16, 89]]</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>[[99, 17], [19, 86]]</td>\n",
       "      <td>0.836248</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.819048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_                                 0.872727  0.847826   \n",
       "df_DF_encoded_                              0.865854  0.840580   \n",
       "df_encoded_minmaxScaled                     0.857939  0.815217   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.857143  0.862559   \n",
       "df_DF_encoded_minmaxScaled                  0.854749  0.811594   \n",
       "df_deleteOutlier_encoded_                   0.851485  0.857820   \n",
       "df_modifiedOutlier_encoded_                 0.847619  0.855204   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.842640  0.853081   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.837209  0.841629   \n",
       "df_DF_deleteOutlier_encoded_                0.836735  0.848341   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.827907  0.832579   \n",
       "df_DF_modifiedOutlier_encoded_              0.826923  0.837104   \n",
       "\n",
       "                                                 confusion_matrix  \\\n",
       "df_encoded_                                 [[90, 23], [19, 144]]   \n",
       "df_DF_encoded_                              [[90, 23], [21, 142]]   \n",
       "df_encoded_minmaxScaled                      [[71, 42], [9, 154]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled        [[95, 15], [14, 87]]   \n",
       "df_DF_encoded_minmaxScaled                  [[71, 42], [10, 153]]   \n",
       "df_deleteOutlier_encoded_                    [[95, 15], [15, 86]]   \n",
       "df_modifiedOutlier_encoded_                 [[100, 16], [16, 89]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled     [[97, 13], [18, 83]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled      [[96, 20], [15, 90]]   \n",
       "df_DF_deleteOutlier_encoded_                 [[97, 13], [19, 82]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled   [[95, 21], [16, 89]]   \n",
       "df_DF_modifiedOutlier_encoded_               [[99, 17], [19, 86]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_                                      0.839948         0.862275   \n",
       "df_DF_encoded_                                   0.833813         0.860606   \n",
       "df_encoded_minmaxScaled                          0.786552         0.785714   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.862511         0.852941   \n",
       "df_DF_encoded_minmaxScaled                       0.783484         0.784615   \n",
       "df_deleteOutlier_encoded_                        0.857561         0.851485   \n",
       "df_modifiedOutlier_encoded_                      0.854844         0.847619   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.851800         0.864583   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.842365         0.818182   \n",
       "df_DF_deleteOutlier_encoded_                     0.846850         0.863158   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.833292         0.809091   \n",
       "df_DF_modifiedOutlier_encoded_                   0.836248         0.834951   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_                                     0.883436  \n",
       "df_DF_encoded_                                  0.871166  \n",
       "df_encoded_minmaxScaled                         0.944785  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.861386  \n",
       "df_DF_encoded_minmaxScaled                      0.938650  \n",
       "df_deleteOutlier_encoded_                       0.851485  \n",
       "df_modifiedOutlier_encoded_                     0.847619  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.821782  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.857143  \n",
       "df_DF_deleteOutlier_encoded_                    0.811881  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.847619  \n",
       "df_DF_modifiedOutlier_encoded_                  0.819048  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_gnb, sort by f1 score and then display it\n",
    "df_f1score_gnb = pd.DataFrame.from_dict(list_f1score_gnb, orient=\"index\")\n",
    "df_f1score_gnb.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_f1score_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_gnb = cross_validate(data_train, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.835802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.813540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.815612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.833205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.811906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.813048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_stdScaled_rounded</th>\n",
       "      <td>0.815598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.833298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.825367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.821034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.814848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.817921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.819055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  f1\n",
       "df_encoded_minmaxScaled                     0.835802\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.813540\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.815612\n",
       "df_DF_encoded_minmaxScaled                  0.833205\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.811906\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.813048\n",
       "df_DF_encoded_stdScaled_rounded             0.815598\n",
       "df_encoded_                                 0.833298\n",
       "df_DF_encoded_                              0.825367\n",
       "df_modifiedOutlier_encoded_                 0.821034\n",
       "df_DF_modifiedOutlier_encoded_              0.814848\n",
       "df_deleteOutlier_encoded_                   0.817921\n",
       "df_DF_deleteOutlier_encoded_                0.819055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_validate_gnb = pd.DataFrame.from_dict(cross_validate_gnb, orient=\"index\")\n",
    "df_cross_validate_gnb.rename(columns={0: \"f1\"}, inplace=True)\n",
    "df_cross_validate_gnb.sort_values(by=[\"f1\"], ascending=False)\n",
    "df_cross_validate_gnb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_mnb = get_score(data_train, data_test, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.862974</td>\n",
       "      <td>0.829710</td>\n",
       "      <td>[[81, 32], [15, 148]]</td>\n",
       "      <td>0.812395</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.907975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>[[91, 19], [11, 90]]</td>\n",
       "      <td>0.859181</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.891089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[81, 32], [20, 143]]</td>\n",
       "      <td>0.797057</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.877301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>[[95, 15], [18, 83]]</td>\n",
       "      <td>0.842709</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.821782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>[[85, 31], [16, 89]]</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>[[81, 35], [18, 87]]</td>\n",
       "      <td>0.763424</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.641350</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>[[60, 56], [29, 76]]</td>\n",
       "      <td>0.620525</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.723810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.610860</td>\n",
       "      <td>[[59, 57], [29, 76]]</td>\n",
       "      <td>0.616215</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.723810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>[[52, 58], [32, 69]]</td>\n",
       "      <td>0.577948</td>\n",
       "      <td>0.543307</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>[[52, 58], [32, 69]]</td>\n",
       "      <td>0.577948</td>\n",
       "      <td>0.543307</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_minmaxScaled                     0.862974  0.829710   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.857143  0.857820   \n",
       "df_DF_encoded_minmaxScaled                  0.846154  0.811594   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.834171  0.843602   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.791111  0.787330   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.766520  0.760181   \n",
       "df_DF_modifiedOutlier_encoded_              0.641350  0.615385   \n",
       "df_modifiedOutlier_encoded_                 0.638655  0.610860   \n",
       "df_deleteOutlier_encoded_                   0.605263  0.573460   \n",
       "df_DF_deleteOutlier_encoded_                0.605263  0.573460   \n",
       "\n",
       "                                                 confusion_matrix  \\\n",
       "df_encoded_minmaxScaled                     [[81, 32], [15, 148]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled        [[91, 19], [11, 90]]   \n",
       "df_DF_encoded_minmaxScaled                  [[81, 32], [20, 143]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled     [[95, 15], [18, 83]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled      [[85, 31], [16, 89]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled   [[81, 35], [18, 87]]   \n",
       "df_DF_modifiedOutlier_encoded_               [[60, 56], [29, 76]]   \n",
       "df_modifiedOutlier_encoded_                  [[59, 57], [29, 76]]   \n",
       "df_deleteOutlier_encoded_                    [[52, 58], [32, 69]]   \n",
       "df_DF_deleteOutlier_encoded_                 [[52, 58], [32, 69]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_minmaxScaled                          0.812395         0.822222   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.859181         0.825688   \n",
       "df_DF_encoded_minmaxScaled                       0.797057         0.817143   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.842709         0.846939   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.790189         0.741667   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.763424         0.713115   \n",
       "df_DF_modifiedOutlier_encoded_                   0.620525         0.575758   \n",
       "df_modifiedOutlier_encoded_                      0.616215         0.571429   \n",
       "df_deleteOutlier_encoded_                        0.577948         0.543307   \n",
       "df_DF_deleteOutlier_encoded_                     0.577948         0.543307   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_minmaxScaled                         0.907975  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.891089  \n",
       "df_DF_encoded_minmaxScaled                      0.877301  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.821782  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.847619  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.828571  \n",
       "df_DF_modifiedOutlier_encoded_                  0.723810  \n",
       "df_modifiedOutlier_encoded_                     0.723810  \n",
       "df_deleteOutlier_encoded_                       0.683168  \n",
       "df_DF_deleteOutlier_encoded_                    0.683168  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_mnb, sort by f1 score and then display it\n",
    "df_f1score_mnb = pd.DataFrame.from_dict(list_f1score_mnb, orient=\"index\")\n",
    "\n",
    "# sort by all columns and display it\n",
    "df_f1score_mnb.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_f1score_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.800001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.797928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.777963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.766334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.781720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.777568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_stdScaled_rounded</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.593662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.591346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.591351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.589181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  f1\n",
       "df_encoded_minmaxScaled                     0.800001\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.797928\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.777963\n",
       "df_DF_encoded_minmaxScaled                  0.766334\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.781720\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.777568\n",
       "df_DF_encoded_stdScaled_rounded                  NaN\n",
       "df_encoded_                                      NaN\n",
       "df_DF_encoded_                                   NaN\n",
       "df_modifiedOutlier_encoded_                 0.593662\n",
       "df_DF_modifiedOutlier_encoded_              0.591346\n",
       "df_deleteOutlier_encoded_                   0.591351\n",
       "df_DF_deleteOutlier_encoded_                0.589181"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_mnb = cross_validate(data_train, MultinomialNB)\n",
    "df_cross_validate_mnb = pd.DataFrame.from_dict(cross_validate_mnb, orient=\"index\")\n",
    "df_cross_validate_mnb.rename(columns={0: \"f1\"}, inplace=True)\n",
    "df_cross_validate_mnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class GaussianNB_Classifier:\n",
    "    def get_prior(self, data):\n",
    "        \"\"\"\n",
    "        data : list data\n",
    "        \"\"\"\n",
    "        n_data = len(data)\n",
    "        prior = Counter(data)\n",
    "        for key in prior.keys():\n",
    "            prior[key] = prior[key] / n_data\n",
    "        return prior\n",
    "\n",
    "    def get_mean_and_std(self, data):\n",
    "        list_columns = data.columns[:-1]\n",
    "        class_column_name = data.columns[-1]\n",
    "        list_class = set(data[class_column_name])\n",
    "\n",
    "        mean = {}\n",
    "        std = {}\n",
    "\n",
    "        for column in list_columns:\n",
    "            for a_class in list_class:\n",
    "                mean[(column, a_class)] = np.mean(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "                std[(column, a_class)] = np.std(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "    def get_gaussian_likelihood(self, data, mean, std):\n",
    "        res = (1/np.sqrt(2*np.pi*(std**2)))\n",
    "        res *= np.exp((-1*((data-mean)**2))/(2*(std**2)))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def training_gaussianNB(self, X, y):\n",
    "        X = X.join(y)\n",
    "        prior = self.get_prior(y)\n",
    "        mean, std = self.get_mean_and_std(X)\n",
    "\n",
    "        list_class = set(y)\n",
    "        list_columns = X.columns[:-1]\n",
    "\n",
    "        model = {}\n",
    "        model['prior'] = prior\n",
    "        model['mean'] = mean\n",
    "        model['std'] = std\n",
    "        model['class'] = list_class\n",
    "        model['columns'] = list_columns\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.training_gaussianNB(X, y)\n",
    "\n",
    "    def get_single_prediction(self, data):\n",
    "        prior = self.model['prior']\n",
    "        mean = self.model['mean']\n",
    "        std = self.model['std']\n",
    "        list_class = self.model['class']\n",
    "        list_columns = self.model['columns']\n",
    "        \n",
    "        posterior = dict.fromkeys(list_class, 1)\n",
    "\n",
    "        for a_class in list_class:\n",
    "            for column in list_columns:    \n",
    "                posterior[a_class] *= self.get_gaussian_likelihood(\n",
    "                    data[column], mean[(column, a_class)], std[(column, a_class)])\n",
    "            posterior[a_class] *= prior[a_class]\n",
    "\n",
    "        kelas_uji = max(posterior, key=posterior.get)\n",
    "        return kelas_uji\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for index, row in X_test.iterrows():\n",
    "            y_pred.append(self.get_single_prediction(row))\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>[[90, 23], [19, 144]]</td>\n",
       "      <td>0.839948</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>0.883436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>[[90, 23], [21, 142]]</td>\n",
       "      <td>0.833813</td>\n",
       "      <td>0.860606</td>\n",
       "      <td>0.871166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.857939</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>[[71, 42], [9, 154]]</td>\n",
       "      <td>0.786552</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.944785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.862559</td>\n",
       "      <td>[[95, 15], [14, 87]]</td>\n",
       "      <td>0.862511</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.861386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[71, 42], [10, 153]]</td>\n",
       "      <td>0.783484</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.938650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>[[95, 15], [15, 86]]</td>\n",
       "      <td>0.857561</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>[[100, 16], [16, 89]]</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>[[97, 13], [18, 83]]</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.821782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>[[96, 20], [15, 90]]</td>\n",
       "      <td>0.842365</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>[[97, 13], [19, 82]]</td>\n",
       "      <td>0.846850</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.811881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>[[95, 21], [16, 89]]</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>[[99, 17], [19, 86]]</td>\n",
       "      <td>0.836248</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.819048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_                                 0.872727  0.847826   \n",
       "df_DF_encoded_                              0.865854  0.840580   \n",
       "df_encoded_minmaxScaled                     0.857939  0.815217   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.857143  0.862559   \n",
       "df_DF_encoded_minmaxScaled                  0.854749  0.811594   \n",
       "df_deleteOutlier_encoded_                   0.851485  0.857820   \n",
       "df_modifiedOutlier_encoded_                 0.847619  0.855204   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.842640  0.853081   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.837209  0.841629   \n",
       "df_DF_deleteOutlier_encoded_                0.836735  0.848341   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.827907  0.832579   \n",
       "df_DF_modifiedOutlier_encoded_              0.826923  0.837104   \n",
       "\n",
       "                                                 confusion_matrix  \\\n",
       "df_encoded_                                 [[90, 23], [19, 144]]   \n",
       "df_DF_encoded_                              [[90, 23], [21, 142]]   \n",
       "df_encoded_minmaxScaled                      [[71, 42], [9, 154]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled        [[95, 15], [14, 87]]   \n",
       "df_DF_encoded_minmaxScaled                  [[71, 42], [10, 153]]   \n",
       "df_deleteOutlier_encoded_                    [[95, 15], [15, 86]]   \n",
       "df_modifiedOutlier_encoded_                 [[100, 16], [16, 89]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled     [[97, 13], [18, 83]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled      [[96, 20], [15, 90]]   \n",
       "df_DF_deleteOutlier_encoded_                 [[97, 13], [19, 82]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled   [[95, 21], [16, 89]]   \n",
       "df_DF_modifiedOutlier_encoded_               [[99, 17], [19, 86]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_                                      0.839948         0.862275   \n",
       "df_DF_encoded_                                   0.833813         0.860606   \n",
       "df_encoded_minmaxScaled                          0.786552         0.785714   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.862511         0.852941   \n",
       "df_DF_encoded_minmaxScaled                       0.783484         0.784615   \n",
       "df_deleteOutlier_encoded_                        0.857561         0.851485   \n",
       "df_modifiedOutlier_encoded_                      0.854844         0.847619   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.851800         0.864583   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.842365         0.818182   \n",
       "df_DF_deleteOutlier_encoded_                     0.846850         0.863158   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.833292         0.809091   \n",
       "df_DF_modifiedOutlier_encoded_                   0.836248         0.834951   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_                                     0.883436  \n",
       "df_DF_encoded_                                  0.871166  \n",
       "df_encoded_minmaxScaled                         0.944785  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.861386  \n",
       "df_DF_encoded_minmaxScaled                      0.938650  \n",
       "df_deleteOutlier_encoded_                       0.851485  \n",
       "df_modifiedOutlier_encoded_                     0.847619  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.821782  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.857143  \n",
       "df_DF_deleteOutlier_encoded_                    0.811881  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.847619  \n",
       "df_DF_modifiedOutlier_encoded_                  0.819048  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gnb_scratch = get_score(data_train, data_test, GaussianNB_Classifier)\n",
    "df_gnb_scratch = pd.DataFrame.from_dict(list_gnb_scratch, orient=\"index\")\n",
    "df_gnb_scratch.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_gnb_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix using seaborn\n",
    "sns.heatmap(df_gnb_scratch.loc['df_encoded_']['confusion_matrix'] ,annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores Test Data: 81.77 (1.94)\n",
      "Recall Scores Test Data: 90.56 (5.61)\n",
      "Precision Scores Test Data: 78.32 (2.43)\n",
      "F1 Scores Test Data: 83.93 (3.33)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data_train['df_encoded_'].drop([\"HeartDisease\"], axis=1)\n",
    "y = data_train['df_encoded_'][\"HeartDisease\"]\n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "model = GaussianNB_Classifier()\n",
    "scoresAccuracy = []\n",
    "scoresRecall = []\n",
    "scoresPrecision = []\n",
    "scoresF1 = []\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "    Y_train, Y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "    x_train = (x_train-np.min(x_train)) / \\\n",
    "        (np.max(x_train)-np.min(x_train)).values\n",
    "    x_test = (x_test-np.min(x_test))/(np.max(x_test)-np.min(x_test)).values\n",
    "    model.fit(x_train, Y_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    test_data_accuracy = accuracy_score(Y_test, y_pred_test)\n",
    "    test_data_recall = recall_score(Y_test, y_pred_test)\n",
    "    test_data_precision = precision_score(Y_test, y_pred_test)\n",
    "    test_data_f1_score = f1_score(Y_test, y_pred_test)\n",
    "    scoresAccuracy.append(test_data_accuracy)\n",
    "    scoresRecall.append(test_data_recall)\n",
    "    scoresPrecision.append(test_data_precision)\n",
    "    scoresF1.append(test_data_f1_score)\n",
    "\n",
    "print('Accuracy Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresAccuracy)*100, np.std(scoresAccuracy)*100))\n",
    "print('Recall Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresRecall)*100, np.std(scoresRecall)*100))\n",
    "print('Precision Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresPrecision)*100, np.std(scoresPrecision)*100))\n",
    "print('F1 Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresF1)*100, np.std(scoresF1)*100))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c59bf3eaebc6870ce0abe767d1553422d9a61b1b748d3c217720a44c48c2ce38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('lrn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
