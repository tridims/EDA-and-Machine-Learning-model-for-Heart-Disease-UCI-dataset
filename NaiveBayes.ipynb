{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries for machine learing and data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# import naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_list = os.listdir(\"Dataset\")\n",
    "file_list = [file.replace(\".csv\", \"\") for file in file_list]\n",
    "\n",
    "# put file names in file_list that have world splitTrain to file_list_train\n",
    "file_list_train = [file for file in file_list if \"splitTrain\" in file]\n",
    "file_list_test = [file for file in file_list if \"splitTest\" in file]\n",
    "\n",
    "data_train = {}\n",
    "for file in file_list_train:\n",
    "    if \"stdScaled\" in file:\n",
    "        continue\n",
    "    data_train[file.replace(\"splitTrain_\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n",
    "\n",
    "data_test = {}\n",
    "for file in file_list_test:\n",
    "    if \"stdScaled\" in file:\n",
    "        continue\n",
    "    data_test[file.replace(\"splitTest_\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import f1 score metric from sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# function to get dictionary of f1 score prediction for each data train and data test using KNeighborsClassifier\n",
    "def get_score(data_train, data_test, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "        try:\n",
    "          X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_train = data_train[key][\"HeartDisease\"]\n",
    "          X_test = data_test[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_test = data_test[key][\"HeartDisease\"]\n",
    "\n",
    "          model = modelNB()\n",
    "          model.fit(X_train, y_train)\n",
    "          y_pred = model.predict(X_test)\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "        try:\n",
    "          performanceData[key] = {'f1_score' : f1_score(y_test, y_pred)}\n",
    "          performanceData[key]['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "          performanceData[key]['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "          performanceData[key]['roc_auc_score'] = roc_auc_score(y_test, y_pred)\n",
    "          performanceData[key]['precision_score'] = precision_score(y_test, y_pred)\n",
    "          performanceData[key]['recall_score'] = recall_score(y_test, y_pred)\n",
    "        except:\n",
    "          print('error masukkan data')\n",
    "        \n",
    "    return performanceData\n",
    "\n",
    "# function to cross validate the model using KFold\n",
    "def cross_validate(data_train, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "        # try:\n",
    "          X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_train = data_train[key][\"HeartDisease\"]\n",
    "\n",
    "          kf = KFold(n_splits=10, shuffle=True)\n",
    "          scores = cross_val_score(modelNB(), X_train, y_train, cv=kf, scoring=\"f1_macro\")\n",
    "          performanceData[key] = scores.mean()\n",
    "\n",
    "        # except:\n",
    "        #   continue\n",
    "            \n",
    "    return performanceData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing already made models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_gnb = get_score(data_train, data_test, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>[[48, 29], [7, 100]]</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[63, 11], [10, 57]]</td>\n",
       "      <td>0.851049</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[47, 30], [7, 100]]</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[63, 11], [12, 55]]</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_minmaxScaled                     0.847458  0.804348   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.819444  0.823129   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.844444  0.851064   \n",
       "df_DF_encoded_minmaxScaled                  0.843882  0.798913   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.819444  0.823129   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.827068  0.836879   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_minmaxScaled                     [[48, 29], [7, 100]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[62, 13], [13, 59]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled       [[63, 11], [10, 57]]   \n",
       "df_DF_encoded_minmaxScaled                  [[47, 30], [7, 100]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[62, 13], [13, 59]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[63, 11], [12, 55]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_minmaxScaled                          0.778978         0.775194   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.823056         0.819444   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.851049         0.838235   \n",
       "df_DF_encoded_minmaxScaled                       0.772485         0.769231   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.823056         0.819444   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.836123         0.833333   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_minmaxScaled                         0.934579  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.819444  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.850746  \n",
       "df_DF_encoded_minmaxScaled                      0.934579  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.819444  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.820896  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_gnb, sort by f1 score and then display it\n",
    "df_f1score_gnb = pd.DataFrame.from_dict(list_f1score_gnb, orient=\"index\")\n",
    "df_f1score_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_gnb = cross_validate(data_train, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.836955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.838177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.823587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.834178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.824047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.817903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "df_encoded_minmaxScaled                     0.836955\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.838177\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.823587\n",
       "df_DF_encoded_minmaxScaled                  0.834178\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.824047\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.817903"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_validate_gnb = pd.DataFrame.from_dict(cross_validate_gnb, orient=\"index\")\n",
    "df_cross_validate_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_mnb = get_score(data_train, data_test, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>[[54, 23], [10, 97]]</td>\n",
       "      <td>0.803920</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.906542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>[[56, 19], [15, 57]]</td>\n",
       "      <td>0.769167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[60, 14], [9, 58]]</td>\n",
       "      <td>0.838241</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[54, 23], [14, 93]]</td>\n",
       "      <td>0.785229</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.869159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>[[55, 20], [16, 56]]</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.815603</td>\n",
       "      <td>[[61, 13], [13, 54]]</td>\n",
       "      <td>0.815147</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_minmaxScaled                     0.854626  0.820652   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.770270  0.768707   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.834532  0.836879   \n",
       "df_DF_encoded_minmaxScaled                  0.834081  0.798913   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.756757  0.755102   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.805970  0.815603   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_minmaxScaled                     [[54, 23], [10, 97]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[56, 19], [15, 57]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled        [[60, 14], [9, 58]]   \n",
       "df_DF_encoded_minmaxScaled                  [[54, 23], [14, 93]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[55, 20], [16, 56]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[61, 13], [13, 54]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_minmaxScaled                          0.803920         0.808333   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.769167         0.750000   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.838241         0.805556   \n",
       "df_DF_encoded_minmaxScaled                       0.785229         0.801724   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.755556         0.736842   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.815147         0.805970   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_minmaxScaled                         0.906542  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.791667  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.865672  \n",
       "df_DF_encoded_minmaxScaled                      0.869159  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.777778  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.805970  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_mnb, sort by f1 score and then display it\n",
    "df_f1score_mnb = pd.DataFrame.from_dict(list_f1score_mnb, orient=\"index\")\n",
    "df_f1score_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.799647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.804317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.771773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.780711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.781516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "df_encoded_minmaxScaled                     0.799647\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.804317\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.790900\n",
       "df_DF_encoded_minmaxScaled                  0.771773\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.780711\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.781516"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_mnb = cross_validate(data_train, MultinomialNB)\n",
    "df_cross_validate_mnb = pd.DataFrame.from_dict(cross_validate_mnb, orient=\"index\")\n",
    "df_cross_validate_mnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class GaussianNB_Classifier:\n",
    "    def get_prior(self, data):\n",
    "        \"\"\"\n",
    "        data : list data\n",
    "        \"\"\"\n",
    "        n_data = len(data)\n",
    "        prior = Counter(data)\n",
    "        for key in prior.keys():\n",
    "            prior[key] = prior[key] / n_data\n",
    "        return prior\n",
    "\n",
    "    def get_mean_and_std(self, data):\n",
    "        list_columns = data.columns[:-1]\n",
    "        class_column_name = data.columns[-1]\n",
    "        list_class = set(data[class_column_name])\n",
    "\n",
    "        mean = {}\n",
    "        std = {}\n",
    "\n",
    "        for column in list_columns:\n",
    "            for a_class in list_class:\n",
    "                mean[(column, a_class)] = np.mean(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "                std[(column, a_class)] = np.std(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "    def get_gaussian_likelihood(self, data, mean, std):\n",
    "        res = (1/np.sqrt(2*np.pi*(std**2)))\n",
    "        res *= np.exp((-1*((data-mean)**2))/(2*(std**2)))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def training_gaussianNB(self, X, y):\n",
    "        X = X.join(y)\n",
    "        prior = self.get_prior(y)\n",
    "        mean, std = self.get_mean_and_std(X)\n",
    "\n",
    "        list_class = set(y)\n",
    "        list_columns = X.columns[:-1]\n",
    "\n",
    "        model = {}\n",
    "        model['prior'] = prior\n",
    "        model['mean'] = mean\n",
    "        model['std'] = std\n",
    "        model['class'] = list_class\n",
    "        model['columns'] = list_columns\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.training_gaussianNB(X, y)\n",
    "\n",
    "    def get_single_prediction(self, data):\n",
    "        prior = self.model['prior']\n",
    "        mean = self.model['mean']\n",
    "        std = self.model['std']\n",
    "        list_class = self.model['class']\n",
    "        list_columns = self.model['columns']\n",
    "        \n",
    "        posterior = dict.fromkeys(list_class, 1)\n",
    "\n",
    "        for a_class in list_class:\n",
    "            for column in list_columns:    \n",
    "                posterior[a_class] *= self.get_gaussian_likelihood(\n",
    "                    data[column], mean[(column, a_class)], std[(column, a_class)])\n",
    "            posterior[a_class] *= prior[a_class]\n",
    "\n",
    "        kelas_uji = max(posterior, key=posterior.get)\n",
    "        return kelas_uji\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for index, row in X_test.iterrows():\n",
    "            y_pred.append(self.get_single_prediction(row))\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>[[48, 29], [7, 100]]</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[63, 11], [10, 57]]</td>\n",
       "      <td>0.851049</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[47, 30], [7, 100]]</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[63, 11], [12, 55]]</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_minmaxScaled                     0.847458  0.804348   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.819444  0.823129   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.844444  0.851064   \n",
       "df_DF_encoded_minmaxScaled                  0.843882  0.798913   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.819444  0.823129   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.827068  0.836879   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_minmaxScaled                     [[48, 29], [7, 100]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[62, 13], [13, 59]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled       [[63, 11], [10, 57]]   \n",
       "df_DF_encoded_minmaxScaled                  [[47, 30], [7, 100]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[62, 13], [13, 59]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[63, 11], [12, 55]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_minmaxScaled                          0.778978         0.775194   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.823056         0.819444   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.851049         0.838235   \n",
       "df_DF_encoded_minmaxScaled                       0.772485         0.769231   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.823056         0.819444   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.836123         0.833333   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_minmaxScaled                         0.934579  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.819444  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.850746  \n",
       "df_DF_encoded_minmaxScaled                      0.934579  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.819444  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.820896  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gnb_scratch = get_score(data_train, data_test, GaussianNB_Classifier)\n",
    "df_gnb_scratch = pd.DataFrame.from_dict(list_f1score_gnb_scratch, orient=\"index\")\n",
    "df_gnb_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores Test Data: 80.38 (2.89)\n",
      "Recall Scores Test Data: 90.12 (4.74)\n",
      "Precision Scores Test Data: 77.90 (5.60)\n",
      "F1 Scores Test Data: 83.30 (2.75)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data_train['df_encoded_minmaxScaled'].drop([\"HeartDisease\"], axis=1)\n",
    "y = data_train['df_encoded_minmaxScaled'][\"HeartDisease\"]\n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "model = GaussianNB_Classifier()\n",
    "scoresAccuracy = []\n",
    "scoresRecall = []\n",
    "scoresPrecision = []\n",
    "scoresF1 = []\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "    Y_train, Y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "    x_train = (x_train-np.min(x_train)) / \\\n",
    "        (np.max(x_train)-np.min(x_train)).values\n",
    "    x_test = (x_test-np.min(x_test))/(np.max(x_test)-np.min(x_test)).values\n",
    "    model.fit(x_train, Y_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    test_data_accuracy = accuracy_score(Y_test, y_pred_test)\n",
    "    test_data_recall = recall_score(Y_test, y_pred_test)\n",
    "    test_data_precision = precision_score(Y_test, y_pred_test)\n",
    "    test_data_f1_score = f1_score(Y_test, y_pred_test)\n",
    "    scoresAccuracy.append(test_data_accuracy)\n",
    "    scoresRecall.append(test_data_recall)\n",
    "    scoresPrecision.append(test_data_precision)\n",
    "    scoresF1.append(test_data_f1_score)\n",
    "\n",
    "print('Accuracy Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresAccuracy)*100, np.std(scoresAccuracy)*100))\n",
    "print('Recall Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresRecall)*100, np.std(scoresRecall)*100))\n",
    "print('Precision Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresPrecision)*100, np.std(scoresPrecision)*100))\n",
    "print('F1 Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresF1)*100, np.std(scoresF1)*100))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c59bf3eaebc6870ce0abe767d1553422d9a61b1b748d3c217720a44c48c2ce38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('lrn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
