{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import usual libraries for machine learing and data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# import naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_list = os.listdir(\"Dataset\")\n",
    "file_list = [file.replace(\".csv\", \"\") for file in file_list]\n",
    "\n",
    "# put file names in file_list that have world splitTrain to file_list_train\n",
    "file_list_train = [file for file in file_list if \"splitTrain\" in file]\n",
    "file_list_test = [file for file in file_list if \"splitTest\" in file]\n",
    "\n",
    "data_train = {}\n",
    "for file in file_list_train:\n",
    "    data_train[file.replace(\"splitTrain_\", \"\").replace(\"splitTrain\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n",
    "\n",
    "data_test = {}\n",
    "for file in file_list_test:\n",
    "    data_test[file.replace(\"splitTest_\", \"\").replace(\"splitTest\", \"\")] = pd.read_csv(\"Dataset/\" + file + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import f1 score metric from sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# function to get dictionary of f1 score prediction for each data train and data test using KNeighborsClassifier\n",
    "def get_score(data_train, data_test, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "        try:\n",
    "          X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_train = data_train[key][\"HeartDisease\"]\n",
    "          X_test = data_test[key].drop([\"HeartDisease\"], axis=1)\n",
    "          y_test = data_test[key][\"HeartDisease\"]\n",
    "\n",
    "          model = modelNB()\n",
    "          model.fit(X_train, y_train)\n",
    "          y_pred = model.predict(X_test)\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "        try:\n",
    "          performanceData[key] = {'f1_score' : f1_score(y_test, y_pred)}\n",
    "          performanceData[key]['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "          performanceData[key]['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "          performanceData[key]['roc_auc_score'] = roc_auc_score(y_test, y_pred)\n",
    "          performanceData[key]['precision_score'] = precision_score(y_test, y_pred)\n",
    "          performanceData[key]['recall_score'] = recall_score(y_test, y_pred)\n",
    "        except:\n",
    "          continue\n",
    "        \n",
    "    return performanceData\n",
    "\n",
    "# function to cross validate the model using KFold\n",
    "def cross_validate(data_train, modelNB):\n",
    "    performanceData = {}\n",
    "    for key in data_train:\n",
    "      try:\n",
    "        X_train = data_train[key].drop([\"HeartDisease\"], axis=1)\n",
    "        y_train = data_train[key][\"HeartDisease\"]\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True)\n",
    "        scores = cross_val_score(modelNB(), X_train, y_train, cv=kf, scoring=\"f1_macro\")\n",
    "        performanceData[key] = scores.mean()\n",
    "      except:\n",
    "        continue\n",
    "            \n",
    "    return performanceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_encoded_minmaxScaled', 'df_modifiedOutlier_encoded_minmaxScaled', 'df_deleteOutlier_encoded_minmaxScaled', 'df_DF_encoded_minmaxScaled', 'df_DF_modifiedOutlier_encoded_minmaxScaled', 'df_DF_deleteOutlier_encoded_minmaxScaled', 'df_DF_encoded_stdScaled_rounded', 'df_encoded_splitTrain', 'df_DF_encoded_splitTrain', 'df_modifiedOutlier_encoded_splitTrain', 'df_DF_modifiedOutlier_encoded_splitTrain', 'df_deleteOutlier_encoded_splitTrain', 'df_DF_deleteOutlier_encoded_splitTrain'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing already made models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_gnb = get_score(data_train, data_test, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>[[59, 18], [12, 95]]</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.858447</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>[[59, 18], [13, 94]]</td>\n",
       "      <td>0.822369</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>[[48, 29], [7, 100]]</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[62, 12], [9, 58]]</td>\n",
       "      <td>0.851755</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[63, 11], [10, 57]]</td>\n",
       "      <td>0.851049</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[47, 30], [7, 100]]</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>[[65, 10], [14, 58]]</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[63, 11], [12, 55]]</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>[[63, 11], [13, 54]]</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[65, 10], [16, 56]]</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_                                 0.863636  0.836957   \n",
       "df_DF_encoded_                              0.858447  0.831522   \n",
       "df_encoded_minmaxScaled                     0.847458  0.804348   \n",
       "df_deleteOutlier_encoded_                   0.846715  0.851064   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.844444  0.851064   \n",
       "df_DF_encoded_minmaxScaled                  0.843882  0.798913   \n",
       "df_modifiedOutlier_encoded_                 0.828571  0.836735   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.827068  0.836879   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.819444  0.823129   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.819444  0.823129   \n",
       "df_DF_deleteOutlier_encoded_                0.818182  0.829787   \n",
       "df_DF_modifiedOutlier_encoded_              0.811594  0.823129   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_                                 [[59, 18], [12, 95]]   \n",
       "df_DF_encoded_                              [[59, 18], [13, 94]]   \n",
       "df_encoded_minmaxScaled                     [[48, 29], [7, 100]]   \n",
       "df_deleteOutlier_encoded_                    [[62, 12], [9, 58]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled       [[63, 11], [10, 57]]   \n",
       "df_DF_encoded_minmaxScaled                  [[47, 30], [7, 100]]   \n",
       "df_modifiedOutlier_encoded_                 [[65, 10], [14, 58]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[63, 11], [12, 55]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[62, 13], [13, 59]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[62, 13], [13, 59]]   \n",
       "df_DF_deleteOutlier_encoded_                [[63, 11], [13, 54]]   \n",
       "df_DF_modifiedOutlier_encoded_              [[65, 10], [16, 56]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_                                      0.827042         0.840708   \n",
       "df_DF_encoded_                                   0.822369         0.839286   \n",
       "df_encoded_minmaxScaled                          0.778978         0.775194   \n",
       "df_deleteOutlier_encoded_                        0.851755         0.828571   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.851049         0.838235   \n",
       "df_DF_encoded_minmaxScaled                       0.772485         0.769231   \n",
       "df_modifiedOutlier_encoded_                      0.836111         0.852941   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.836123         0.833333   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.823056         0.819444   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.823056         0.819444   \n",
       "df_DF_deleteOutlier_encoded_                     0.828661         0.830769   \n",
       "df_DF_modifiedOutlier_encoded_                   0.822222         0.848485   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_                                     0.887850  \n",
       "df_DF_encoded_                                  0.878505  \n",
       "df_encoded_minmaxScaled                         0.934579  \n",
       "df_deleteOutlier_encoded_                       0.865672  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.850746  \n",
       "df_DF_encoded_minmaxScaled                      0.934579  \n",
       "df_modifiedOutlier_encoded_                     0.805556  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.820896  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.819444  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.819444  \n",
       "df_DF_deleteOutlier_encoded_                    0.805970  \n",
       "df_DF_modifiedOutlier_encoded_                  0.777778  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_gnb, sort by f1 score and then display it\n",
    "df_f1score_gnb = pd.DataFrame.from_dict(list_f1score_gnb, orient=\"index\")\n",
    "df_f1score_gnb.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_f1score_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_gnb = cross_validate(data_train, GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.842173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.833498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.834503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.835974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.826193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_stdScaled_rounded</th>\n",
       "      <td>0.811795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.837883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.831924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.827180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.828285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.824637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.828245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  f1\n",
       "df_encoded_minmaxScaled                     0.842173\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.833498\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.834503\n",
       "df_DF_encoded_minmaxScaled                  0.835974\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.827719\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.826193\n",
       "df_DF_encoded_stdScaled_rounded             0.811795\n",
       "df_encoded_                                 0.837883\n",
       "df_DF_encoded_                              0.831924\n",
       "df_modifiedOutlier_encoded_                 0.827180\n",
       "df_DF_modifiedOutlier_encoded_              0.828285\n",
       "df_deleteOutlier_encoded_                   0.824637\n",
       "df_DF_deleteOutlier_encoded_                0.828245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_validate_gnb = pd.DataFrame.from_dict(cross_validate_gnb, orient=\"index\")\n",
    "df_cross_validate_gnb.rename(columns={0: \"f1\"}, inplace=True)\n",
    "df_cross_validate_gnb.sort_values(by=[\"f1\"], ascending=False)\n",
    "df_cross_validate_gnb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_f1score_mnb = get_score(data_train, data_test, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>[[54, 23], [10, 97]]</td>\n",
       "      <td>0.803920</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.906542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[60, 14], [9, 58]]</td>\n",
       "      <td>0.838241</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[54, 23], [14, 93]]</td>\n",
       "      <td>0.785229</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.869159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.815603</td>\n",
       "      <td>[[61, 13], [13, 54]]</td>\n",
       "      <td>0.815147</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[[63, 12], [16, 56]]</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>[[60, 15], [17, 55]]</td>\n",
       "      <td>0.781944</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>[[56, 19], [15, 57]]</td>\n",
       "      <td>0.769167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>[[55, 20], [16, 56]]</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>[[58, 16], [17, 50]]</td>\n",
       "      <td>0.765026</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.730496</td>\n",
       "      <td>[[55, 19], [19, 48]]</td>\n",
       "      <td>0.729831</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_minmaxScaled                     0.854626  0.820652   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.834532  0.836879   \n",
       "df_DF_encoded_minmaxScaled                  0.834081  0.798913   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.805970  0.815603   \n",
       "df_modifiedOutlier_encoded_                 0.800000  0.809524   \n",
       "df_DF_modifiedOutlier_encoded_              0.774648  0.782313   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.770270  0.768707   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.756757  0.755102   \n",
       "df_deleteOutlier_encoded_                   0.751880  0.765957   \n",
       "df_DF_deleteOutlier_encoded_                0.716418  0.730496   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_minmaxScaled                     [[54, 23], [10, 97]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled        [[60, 14], [9, 58]]   \n",
       "df_DF_encoded_minmaxScaled                  [[54, 23], [14, 93]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[61, 13], [13, 54]]   \n",
       "df_modifiedOutlier_encoded_                 [[63, 12], [16, 56]]   \n",
       "df_DF_modifiedOutlier_encoded_              [[60, 15], [17, 55]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[56, 19], [15, 57]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[55, 20], [16, 56]]   \n",
       "df_deleteOutlier_encoded_                   [[58, 16], [17, 50]]   \n",
       "df_DF_deleteOutlier_encoded_                [[55, 19], [19, 48]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_minmaxScaled                          0.803920         0.808333   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.838241         0.805556   \n",
       "df_DF_encoded_minmaxScaled                       0.785229         0.801724   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.815147         0.805970   \n",
       "df_modifiedOutlier_encoded_                      0.808889         0.823529   \n",
       "df_DF_modifiedOutlier_encoded_                   0.781944         0.785714   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.769167         0.750000   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.755556         0.736842   \n",
       "df_deleteOutlier_encoded_                        0.765026         0.757576   \n",
       "df_DF_deleteOutlier_encoded_                     0.729831         0.716418   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_minmaxScaled                         0.906542  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.865672  \n",
       "df_DF_encoded_minmaxScaled                      0.869159  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.805970  \n",
       "df_modifiedOutlier_encoded_                     0.777778  \n",
       "df_DF_modifiedOutlier_encoded_                  0.763889  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.791667  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.777778  \n",
       "df_deleteOutlier_encoded_                       0.746269  \n",
       "df_DF_deleteOutlier_encoded_                    0.716418  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from list_f1score_mnb, sort by f1 score and then display it\n",
    "df_f1score_mnb = pd.DataFrame.from_dict(list_f1score_mnb, orient=\"index\")\n",
    "\n",
    "# sort by all columns and display it\n",
    "df_f1score_mnb.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_f1score_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.797069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.803955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.789589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.773249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.777920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.777220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_stdScaled_rounded</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.779216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.790967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.785298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  f1\n",
       "df_encoded_minmaxScaled                     0.797069\n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.803955\n",
       "df_deleteOutlier_encoded_minmaxScaled       0.789589\n",
       "df_DF_encoded_minmaxScaled                  0.773249\n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.777920\n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.777220\n",
       "df_DF_encoded_stdScaled_rounded                  NaN\n",
       "df_encoded_                                      NaN\n",
       "df_DF_encoded_                                   NaN\n",
       "df_modifiedOutlier_encoded_                 0.779216\n",
       "df_DF_modifiedOutlier_encoded_              0.780374\n",
       "df_deleteOutlier_encoded_                   0.790967\n",
       "df_DF_deleteOutlier_encoded_                0.785298"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_mnb = cross_validate(data_train, MultinomialNB)\n",
    "df_cross_validate_mnb = pd.DataFrame.from_dict(cross_validate_mnb, orient=\"index\")\n",
    "df_cross_validate_mnb.rename(columns={0: \"f1\"}, inplace=True)\n",
    "df_cross_validate_mnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class GaussianNB_Classifier:\n",
    "    def get_prior(self, data):\n",
    "        \"\"\"\n",
    "        data : list data\n",
    "        \"\"\"\n",
    "        n_data = len(data)\n",
    "        prior = Counter(data)\n",
    "        for key in prior.keys():\n",
    "            prior[key] = prior[key] / n_data\n",
    "        return prior\n",
    "\n",
    "    def get_mean_and_std(self, data):\n",
    "        list_columns = data.columns[:-1]\n",
    "        class_column_name = data.columns[-1]\n",
    "        list_class = set(data[class_column_name])\n",
    "\n",
    "        mean = {}\n",
    "        std = {}\n",
    "\n",
    "        for column in list_columns:\n",
    "            for a_class in list_class:\n",
    "                mean[(column, a_class)] = np.mean(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "                std[(column, a_class)] = np.std(\n",
    "                    data.loc[data[class_column_name] == a_class][column])\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "    def get_gaussian_likelihood(self, data, mean, std):\n",
    "        res = (1/np.sqrt(2*np.pi*(std**2)))\n",
    "        res *= np.exp((-1*((data-mean)**2))/(2*(std**2)))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def training_gaussianNB(self, X, y):\n",
    "        X = X.join(y)\n",
    "        prior = self.get_prior(y)\n",
    "        mean, std = self.get_mean_and_std(X)\n",
    "\n",
    "        list_class = set(y)\n",
    "        list_columns = X.columns[:-1]\n",
    "\n",
    "        model = {}\n",
    "        model['prior'] = prior\n",
    "        model['mean'] = mean\n",
    "        model['std'] = std\n",
    "        model['class'] = list_class\n",
    "        model['columns'] = list_columns\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.training_gaussianNB(X, y)\n",
    "\n",
    "    def get_single_prediction(self, data):\n",
    "        prior = self.model['prior']\n",
    "        mean = self.model['mean']\n",
    "        std = self.model['std']\n",
    "        list_class = self.model['class']\n",
    "        list_columns = self.model['columns']\n",
    "        \n",
    "        posterior = dict.fromkeys(list_class, 1)\n",
    "\n",
    "        for a_class in list_class:\n",
    "            for column in list_columns:    \n",
    "                posterior[a_class] *= self.get_gaussian_likelihood(\n",
    "                    data[column], mean[(column, a_class)], std[(column, a_class)])\n",
    "            posterior[a_class] *= prior[a_class]\n",
    "\n",
    "        kelas_uji = max(posterior, key=posterior.get)\n",
    "        return kelas_uji\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for index, row in X_test.iterrows():\n",
    "            y_pred.append(self.get_single_prediction(row))\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_encoded_</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>[[59, 18], [12, 95]]</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_</th>\n",
       "      <td>0.858447</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>[[59, 18], [13, 94]]</td>\n",
       "      <td>0.822369</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_encoded_minmaxScaled</th>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>[[48, 29], [7, 100]]</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_</th>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[62, 12], [9, 58]]</td>\n",
       "      <td>0.851755</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.865672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>[[63, 11], [10, 57]]</td>\n",
       "      <td>0.851049</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_encoded_minmaxScaled</th>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>[[47, 30], [7, 100]]</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.934579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>[[65, 10], [14, 58]]</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>[[63, 11], [12, 55]]</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_minmaxScaled</th>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[62, 13], [13, 59]]</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_deleteOutlier_encoded_</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>[[63, 11], [13, 54]]</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_DF_modifiedOutlier_encoded_</th>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.823129</td>\n",
       "      <td>[[65, 10], [16, 56]]</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_score  accuracy  \\\n",
       "df_encoded_                                 0.863636  0.836957   \n",
       "df_DF_encoded_                              0.858447  0.831522   \n",
       "df_encoded_minmaxScaled                     0.847458  0.804348   \n",
       "df_deleteOutlier_encoded_                   0.846715  0.851064   \n",
       "df_deleteOutlier_encoded_minmaxScaled       0.844444  0.851064   \n",
       "df_DF_encoded_minmaxScaled                  0.843882  0.798913   \n",
       "df_modifiedOutlier_encoded_                 0.828571  0.836735   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    0.827068  0.836879   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     0.819444  0.823129   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  0.819444  0.823129   \n",
       "df_DF_deleteOutlier_encoded_                0.818182  0.829787   \n",
       "df_DF_modifiedOutlier_encoded_              0.811594  0.823129   \n",
       "\n",
       "                                                confusion_matrix  \\\n",
       "df_encoded_                                 [[59, 18], [12, 95]]   \n",
       "df_DF_encoded_                              [[59, 18], [13, 94]]   \n",
       "df_encoded_minmaxScaled                     [[48, 29], [7, 100]]   \n",
       "df_deleteOutlier_encoded_                    [[62, 12], [9, 58]]   \n",
       "df_deleteOutlier_encoded_minmaxScaled       [[63, 11], [10, 57]]   \n",
       "df_DF_encoded_minmaxScaled                  [[47, 30], [7, 100]]   \n",
       "df_modifiedOutlier_encoded_                 [[65, 10], [14, 58]]   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled    [[63, 11], [12, 55]]   \n",
       "df_modifiedOutlier_encoded_minmaxScaled     [[62, 13], [13, 59]]   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled  [[62, 13], [13, 59]]   \n",
       "df_DF_deleteOutlier_encoded_                [[63, 11], [13, 54]]   \n",
       "df_DF_modifiedOutlier_encoded_              [[65, 10], [16, 56]]   \n",
       "\n",
       "                                            roc_auc_score  precision_score  \\\n",
       "df_encoded_                                      0.827042         0.840708   \n",
       "df_DF_encoded_                                   0.822369         0.839286   \n",
       "df_encoded_minmaxScaled                          0.778978         0.775194   \n",
       "df_deleteOutlier_encoded_                        0.851755         0.828571   \n",
       "df_deleteOutlier_encoded_minmaxScaled            0.851049         0.838235   \n",
       "df_DF_encoded_minmaxScaled                       0.772485         0.769231   \n",
       "df_modifiedOutlier_encoded_                      0.836111         0.852941   \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled         0.836123         0.833333   \n",
       "df_modifiedOutlier_encoded_minmaxScaled          0.823056         0.819444   \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled       0.823056         0.819444   \n",
       "df_DF_deleteOutlier_encoded_                     0.828661         0.830769   \n",
       "df_DF_modifiedOutlier_encoded_                   0.822222         0.848485   \n",
       "\n",
       "                                            recall_score  \n",
       "df_encoded_                                     0.887850  \n",
       "df_DF_encoded_                                  0.878505  \n",
       "df_encoded_minmaxScaled                         0.934579  \n",
       "df_deleteOutlier_encoded_                       0.865672  \n",
       "df_deleteOutlier_encoded_minmaxScaled           0.850746  \n",
       "df_DF_encoded_minmaxScaled                      0.934579  \n",
       "df_modifiedOutlier_encoded_                     0.805556  \n",
       "df_DF_deleteOutlier_encoded_minmaxScaled        0.820896  \n",
       "df_modifiedOutlier_encoded_minmaxScaled         0.819444  \n",
       "df_DF_modifiedOutlier_encoded_minmaxScaled      0.819444  \n",
       "df_DF_deleteOutlier_encoded_                    0.805970  \n",
       "df_DF_modifiedOutlier_encoded_                  0.777778  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gnb_scratch = get_score(data_train, data_test, GaussianNB_Classifier)\n",
    "df_gnb_scratch = pd.DataFrame.from_dict(list_gnb_scratch, orient=\"index\")\n",
    "df_gnb_scratch.sort_values(by=[\"f1_score\", \"accuracy\"], ascending=[False, False], inplace=True)\n",
    "df_gnb_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores Test Data: 80.38 (2.89)\n",
      "Recall Scores Test Data: 90.12 (4.74)\n",
      "Precision Scores Test Data: 77.90 (5.60)\n",
      "F1 Scores Test Data: 83.30 (2.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "/home/tridi/anaconda3/envs/lrn/lib/python3.9/site-packages/numpy/core/fromnumeric.py:85: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data_train['df_encoded_'].drop([\"HeartDisease\"], axis=1)\n",
    "y = data_train['df_encoded_'][\"HeartDisease\"]\n",
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "model = GaussianNB_Classifier()\n",
    "scoresAccuracy = []\n",
    "scoresRecall = []\n",
    "scoresPrecision = []\n",
    "scoresF1 = []\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "    Y_train, Y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "    x_train = (x_train-np.min(x_train)) / \\\n",
    "        (np.max(x_train)-np.min(x_train)).values\n",
    "    x_test = (x_test-np.min(x_test))/(np.max(x_test)-np.min(x_test)).values\n",
    "    model.fit(x_train, Y_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    test_data_accuracy = accuracy_score(Y_test, y_pred_test)\n",
    "    test_data_recall = recall_score(Y_test, y_pred_test)\n",
    "    test_data_precision = precision_score(Y_test, y_pred_test)\n",
    "    test_data_f1_score = f1_score(Y_test, y_pred_test)\n",
    "    scoresAccuracy.append(test_data_accuracy)\n",
    "    scoresRecall.append(test_data_recall)\n",
    "    scoresPrecision.append(test_data_precision)\n",
    "    scoresF1.append(test_data_f1_score)\n",
    "\n",
    "print('Accuracy Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresAccuracy)*100, np.std(scoresAccuracy)*100))\n",
    "print('Recall Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresRecall)*100, np.std(scoresRecall)*100))\n",
    "print('Precision Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresPrecision)*100, np.std(scoresPrecision)*100))\n",
    "print('F1 Scores Test Data: %.2f (%.2f)' %\n",
    "      (np.mean(scoresF1)*100, np.std(scoresF1)*100))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c59bf3eaebc6870ce0abe767d1553422d9a61b1b748d3c217720a44c48c2ce38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('lrn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
